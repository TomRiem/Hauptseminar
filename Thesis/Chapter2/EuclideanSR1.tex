\chapter{Euclidean Trust-Region Symmetric Rank-One Method}

In the Euclidean optimization a key problem is minimizing a real-valued function $f$ over the Euclidean space $\mathbb{R}^n$ ($n \geq 1$), i.e. our focus and efforts are centred on solving 
\begin{equation}\label{OptimizationProblem}
    \min f(x), \quad x \in \mathbb{R}^n
\end{equation}  
where $f \colon \; \mathbb{R}^n \to \mathbb{R}$ is a smooth function, by which we generally mean functions whose second derivatives exist and are continuous or formally $f \in C^2(\mathbb{R}^n)$, unless otherwise stated. \cref{OptimizationProblem} is called a (nonlinear) unconstrained optimization problem. \\
The Trust-Region method is one of the most important numerical optimization methods in solving \cref{OptimizationProblem}. At each iterate $x_k$, we first define a qudratic model 
\begin{equation}\label{QudraticModel}
    m_k(s) = f(x_k) + \nabla f(x_k)^{\mathrm{T}} s + \frac{1}{2} s^{\mathrm{T}} H_k s,
\end{equation}
where $\nabla f(x_k)$ denotes the gradient of the objective function $f$ at the current iterate $x_k$ and $H_k \in  \mathbb{R}^{n \times n}$ is a symmetric matrix. The difference between \cref{QudraticModel} and the objective function is $\mathcal{O}(\lVert s \rVert^{2}_2)$, which is small when $\lVert s \rVert_2$ is small. If $H_k$ is equal to the true Hessian $\nabla^2 f(x_k)$ at the current iterate, the approximation error in the model $m_k$ is $\mathcal{O}(\lVert s \rVert^{3}_2)$, so this model is especially accurate when $\lVert s \rVert_2$ is small. This choice $H_k = \nabla^2 f(x_k)$ leads to the Trust-Region Newton method \cite[p.~68]{NocedalWright:2006}. \\
The model \cref{QudraticModel} is easier to handle than the objective function $f$ and its purpose is to approximate $f$ within a suitable neighbourhood of the current iterate $x_k$, which we refer to as the trust-region. The trust-region is defined by
\begin{equation}\label{TrustRegion}
    \{ x \in \mathbb{R}^n \colon \ \lVert x - x_k \rVert_2 \leq \Delta_k \}
\end{equation}
where $\Delta_k > 0$ is the trust-region radius \cite[p.~115]{ConnGouldToint:2000}. The region \cref{TrustRegion} is so called because we trust the model \cref{QudraticModel} to be a faithful representation of the objective function only in this region \cite[p.~2]{ConnGouldToint:2000}. \\
Given the model \cref{QudraticModel} and its trust-region \cref{TrustRegion}, we next seek a step $s_k$ with the aim of reducing the model \cref{QudraticModel} while satisfying the bound $\lVert s_k \rVert_2 \leq \Delta_k$, this means in each iteration we compute the minimizer of the so-called Trust-Region subproblem
\begin{equation}\label{trsubproblem}
    s_k = \arg \min_{\lVert s \rVert_2 \leq \Delta_k} m_k(s) = \arg \min_{\lVert s \rVert_2 \leq \Delta_k} f(x_k) + \nabla f(x_k)^{\mathrm{T}} s + \frac{1}{2} s^{\mathrm{T}} H_k s.
\end{equation}
In practice, the step $s_k$ is just a approximate solution of \cref{trsubproblem}, which is required to be accurate enough that there exist positive constants $\sigma_1$ and $\sigma_2$, sucht that 
\begin{equation}\label{accuracy1}
    m_k(0) - m_k(s_k) \geq \sigma_1 \ \lVert \nabla f(x_k) \rVert_2 \ \min \{ \Delta_k, \sigma_2 \ \frac{\lVert \nabla f(x_k) \rVert}{\lVert H_k \rVert} \} 
\end{equation} 
and
\begin{equation}\label{accuracy2}
    \text{whenever } \lVert s_k \rVert_2 < 0.8 \ \Delta_k, \text{ then } H_k s_k = - \nabla f(x_k)
\end{equation}
hold for all $k = 0, 1, \ldots$. These conditions are satisfied if \cref{trsubproblem} is solved exactly and by most of the so-called inner iteration methods that are used in practice \cite[p.~1027]{ByrdKhalfanSchnabel:1996}. A standard method for this is the so-called truncated conjugate-gradient method, which is an “inverse-free” algorithm, as it only uses $H_k$, that achieves at least as much reduction in the model $m_k$ as the reduction achieved by the so-called Cauchy point (see \cite[4.1~Algorithms~based~on~the~cauchy~point]{NocedalWright:2006}). This point is simply the minimizer of $m_k$ along the steepest descent direction $- \nabla f(x_k)$ subject to the trust-region bound \cite[p.~71]{NocedalWright:2006}. \\
Having determined the step $s_k$, we get the candidate for the next iterate by adding $s_k$ to the current iterate $x_k$, i.e. we compute 
\begin{equation}\label{candidate}
    \widetilde{x}_{k+1} = x_k + s_k.
\end{equation}
We are only talking about a candidate because we make the acceptance of $\widetilde{x}_{k+1}$ as the next iterate $x_{k+1}$ dependent on the agreement between the objective function $f$ and the quadratic model $m_k$ for the step $s_k$. For that we compute at each iteration the quotient
\begin{equation}\label{agreement}
    \rho_k = \frac{f(x_k) - f(x_k + s_k)}{m_k(0) - m_k(s_k)} = \frac{f(x_k) - f(\widetilde{x}_{k+1})}{m_k(0) - m_k(s_k)}.
\end{equation}
The numerator is called the actual reduction, and the denominator is called the predicted reduction (because it is the reduction in $f$ predicted by the model $m_k$). \\
In general, the candidate $\widetilde{x}_{k+1}$ is accepted as the next iterate $x_{k+1}$ if $\rho_k$ is greater than a chosen constant $\rho^{\prime} \in [0 , \frac{1}{4})$. We point out that since the step $s_k$ is obtained by minimizing the model $m_k$ over a region that includes $s = 0$, the predicted reduction will always be nonnegative. Hence, if $\rho_k$ is negative, the new objective value $f(x_k + s_k)$ is greater than the current value $f(x_k)$, so the step must be rejected \cite[p.~68-69]{NocedalWright:2006}. \\
At the end of each iteration, the trust-region radius $\Delta_k$ is updated. There are diverse heuristics for this, which in general base this choice on $\rho_k$ and the norm of the step $s_k$. We consider the strategy: If $\rho_k$ is less than $0.1$, which indicates that the model $m_k$ inside the current trust-region represents the objective function $f$ poorly, we decrease the radius, i.e. $\Delta_{k+1} < \Delta_k$. If $\rho_k$ is greater than $0.75$, indicating that the model $m_k$ represents the objective function $f$ well enough inside the current trust-region, and $\lVert s_k \rVert_2 \geq 0.8 \ \Delta_k$, indicating the current step $s_k$ is pretty close to the boundary of the current trust-region, we increase the radius, i.e. $\Delta_{k+1} > \Delta_k$. Otherwise, the radius is not changed, i.e. $\Delta_{k+1} = \Delta_k$. We point out that the size of the trust-region is critical to the effectiveness of each step. A trust-region that is too small could prevent a substantial step that will move it much closer to the minimizer of $f$ from being taken. In a trust region that is too large, the minimizer of the model $m_k$ could be too far away from the minimizer of the objective function $f$ and the resulting step could be rejected. In general, the direction of the step changes whenever the size of the trust-region is altered \cite[p.~67]{NocedalWright:2006}. \\

The convergence results of a Trust-Region method depend (among other things) on the quadratic term $H_k$ in the model $m_k$. As already mentioned, a possible choice would be the Hessian matrix, i.e. $H_k = \nabla^2 f(x_k)$. If the iterates $\{ x_k \}_k$ generated by the resulting algorithm converge to a point $x^*$ satisfying second-order sufficient conditions, it can be shown that the rate of convergence is superlinear (see \cite[4.4~Local~convergence~of~trust-region~Newton~methods]{NocedalWright:2006}). \\
But in practice there are cases where the Hessian matrix of the objective function is too costly to use, or even does not exist at all. Therefore, one is interested in an approximation of the second derivative of the objective function. \\
A promising approach is provided by the quasi-Newton methods, which are based on the well-known Newton's method. These linesearch methods generate a search direction by minimizing a quadratic model $m_k$ of the objective function $f$ (as for trust-region methods, but without the boundary of the trust region), where the quadratic term $H_k \in \mathbb{R}^{n \times n}$ is an approximation of $\nabla^{2} f(x_k)$. This matrix $H_k$ is not calculated anew in each iteration, but $H_k$ is updated to a new matrix $H_{k+1} \in \mathbb{R}^{n \times n}$ using the information about the curvature of the objective function $f$ obtained by the difference of the iterates, which we denote by $s_k = x_{k+1} - x_k \in \mathbb{R}^n$, and by the difference of the gradients at the iterates, which we denote by $y_k = \nabla f(x_{k+1}) - \nabla f(x_k) \in \mathbb{R}^n$. It is required that the new matrix $H_{k+1}$ generated by the corresponding update fulfills the so-called quasi-Newton equation, which requires that
\begin{equation}\label{quasi-NewtonEquation}
    H_{k+1} (x_{k+1} - x_k) = \nabla f(x_{k+1}) - \nabla f(x_k) \quad \text{or} \quad H_{k+1} s_k = y_k
\end{equation}
holds. By satisfying \cref{quasi-NewtonEquation}, one expects better approximation properties of the matrix $H_{k+1}$ for the next iteration. The fact that the matrix $H_{k+1}$ satisfies \cref{quasi-NewtonEquation} for all $k = 0, 1, \ldots$ is the distinguishing feature of quasi-Newton methods. \\

There are several quasi-Newton update formulae that satisfy \cref{quasi-NewtonEquation}. Some of them are so-called rank-two updates, since they add a rank-two matrix to the current approximation $H_k$, which ensure under additional assumptions that the symmetry and positive definiteness of the matrix $H_k$ is inherited, which is attractive for linesearch methods, since the resulting search direction is then a descent direction. \\
But there is also a simpler rank-one update that just maintains symmetry of the matrix $H_k$. It's the so-called Symmetric Rank-One, short SR1, update which generates $H_{k+1}$ satisfying \cref{quasi-NewtonEquation} by adding a rank-one matrix to $H_k$. Good numerical results have been obtained with algorithms based on the SR1 update, which is given by
\begin{equation}\label{directSR1formula}
    H^\mathrm{SR1}_{k+1} = H^\mathrm{SR1}_k + \frac{(y_k - H^\mathrm{SR1}_k s_k) (y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}}}{(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k}.
\end{equation}
It is easy to see in that even if $H^\mathrm{SR1}_k$ is positive definite, $H^\mathrm{SR1}_{k+1}$ may not have the same property. If and only if $(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k > 0$, the SR1 update retains positive definiteness. However, this condition is difficult to guarantee. It can be shown, if $(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k \neq 0$ holds, that \cref{directSR1formula} is the unique symmetric rank-one formula, so that $H^\mathrm{SR1}_{k+1}$ satisfies \cref{quasi-NewtonEquation} \cite[p.~144-145]{NocedalWright:2006}. \\

To be able to use the SR1 update in a Trust-Region approach we have to change the definitions of $s_k$ and $y_k$ through which we get the information about the curvature of the objective function $f$. For $s_k$ we use the (approximate) minimizer of the Trust-Region subproblem, \cref{trsubproblem}, which represents the difference of the current iterate to the candidate, i.e. $s_k = \widetilde{x}_{k+1} - x_k$, and we set $y_k = \nabla f(\widetilde{x}_{k+1}) - \nabla f(x_k)$, which means that the gradient has to be evaluated at the candidate $\widetilde{x}_{k+1}$ in each iteration. \\

The main drawback of the SR1 update is that the denominator in \cref{directSR1formula} can vanish. This disadvantage can result in serious numerical difficulties, which restrict the applications of this update. Nevertheless, the matrices generated by \cref{directSR1formula} tend to be good approximations of the true Hessian matrix \cite[p.~145]{NocedalWright:2006}. \\
For the vanishing denominator in \cref{directSR1formula} we can use a strategy to prevent the breakdown of the resulting method and the occurrence of numerical instabilities. It has been observed in practice that it performs well simply by skipping the update if the denominator is small. More specifically, the update \cref{directSR1formula} is applied only if 
\begin{equation}\label{safeguard}
    \lvert (y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k \lvert \; \geq \; r \; \lVert s_k \rVert_2 \lVert y_k - H^\mathrm{SR1}_k s_k \rVert_2 
\end{equation}
holds, where $r \in (0, 1)$ is a small number, e.g. $r = 10^{−8}$. Most implementations of the SR1 update use a skipping rule of this kind. The condition $(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k \approx 0$ occurs infrequently, since it requires certain vectors to be aligned in a specific way. When it occurs, skipping the update appears to have no negative effects on the iteration, since the skipping condition implies that $s^{\mathrm{T}}_k \tilde{G}_k s_k \approx s^{\mathrm{T}}_k H^\mathrm{SR1}_k s_k$, where $\tilde{G}_k$ is the average Hessian over the last step (see \cite[(6.11)]{NocedalWright:2006} with $\alpha_k p_k = s_k$), which indicates that the curvature of $H^\mathrm{SR1}_k$ along $s_k$ is already correct \cite[p.~145-146]{NocedalWright:2006}. \\

All these concepts and heuristics now discussed lead to \cref{TR-SR1Method}.
\begin{algorithm}[H]
    \caption{Trust-Region Symmetric Rank-One Method}\label{TR-SR1Method}
    \begin{algorithmic}[1]
        \State Continuously differentiable real-valued function $f$ on $\mathbb{R}^n$, bounded below; initial iterate $x_0 \in \mathbb{R}^n$; initial symmetric matrix $H^{\mathrm{SR1}}_0 \in \mathbb{R}^{n \times n}$; initial trust-region radius $\Delta_0 > 0$; safeguard tolerance $r \in (0,1)$; acceptance tolerance $\rho^{\prime} \in (0, 0.1)$; trust-region decrease factor $\tau_1 \in (0,1)$; trust-region increase factor $\tau_2 > 1$; convergence tolerance $\varepsilon > 0$. Set $k = 0$.
        \While{$\lVert \nabla f(x_k) \rVert_2 > \varepsilon$}
            \State Obtain $s_k$ by (approximately) solving \cref{trsubproblem} using $H_k = H^{\mathrm{SR1}}_k$.
            \State Set $\widetilde{x}_{k+1} = x_k + s_k$ and $y_k = \nabla f(\widetilde{x}_{k+1}) - \nabla f(x_k)$.
            \If{\cref{safeguard} holds}
                \State Compute $H^{\mathrm{SR1}}_{k+1} \in \mathbb{R}^{n \times n}$ by means of \cref{directSR1formula}. 
			\Else 
				\State Set $H^{\mathrm{SR1}}_{k+1} = H^{\mathrm{SR1}}_k$.
            \EndIf 
            \State Compute $\rho_k = \frac{f(x_k) - f(\widetilde{x}_{k+1})}{m_k(0) - m_k(s_k)}$.
            \If{$\rho_k > \rho^{\prime}$}
                \State Set $x_{k+1} = \widetilde{x}_{k+1}$.
			\Else 
				\State Set $x_{k+1} = x_k$.
            \EndIf 
            \If{$\rho_k > 0.75$} 
                \If{$\lVert s_k \rVert_2 \geq 0.8 \ \Delta_k$}
                    \State Set $\Delta_{k+1} = \tau_2 \ \Delta_k$.
                \Else 
                    \State Set $\Delta_{k+1} = \Delta_k$.
                \EndIf 
			\Else 
                \If{$\rho_k < 0.1$}
                    \State Set $\Delta_{k+1} = \tau_1 \ \Delta_k$.
                \Else 
                    \State Set $\Delta_{k+1} = \Delta_k$.
                \EndIf 
            \EndIf 
            \State Set $k = k+1$.
        \EndWhile
        \State \textbf{Return} $x_k$.
    \end{algorithmic}
\end{algorithm}
We see that in \cref{TR-SR1Method} the matrix $H^{\mathrm{SR1}}_k$ is updated whether we accept the candidate $\widetilde{x}_{k+1}$ or not. This is because in order to obtain a fast rate of convergence, it is important for the matrix $H^{\mathrm{SR1}}_k$ to be updated even along a failed step $s_k$, i.e. $x_{k+1} = x_k$ but $H^{\mathrm{SR1}}_{k+1}$ is generated by \cref{directSR1formula}. Such updates along these failed directions seem to be necessary for the convergence analysis because if the approximation of the Hessian is incorrect along such a direction and is not updated, very similar steps could be generated repeatedly later. Such steps would lead to candidates which would be rejected, which in turn would lead to a reduction of the trust-region in these iterations. This could prevent a superlinear step from being taken even though the Hessian approximation is accurate enough, since the trust-region is potentially small enough that it would interfere \cite[p.~1028]{ByrdKhalfanSchnabel:1996}. \\
We summarize the most important results of the convergence analysis of \cref{TR-SR1Method}, which can be found in \cite{ByrdKhalfanSchnabel:1996}. To prove the global convergence of \cref{TR-SR1Method}, we need the following assumptions:  
\begin{assumption}[{\cite[(A1)+(A3)]{ByrdKhalfanSchnabel:1996}}]\label{AssumptionsGlobalConvergence} \ \\[-1.5\baselineskip]
    \begin{enumerate}
        \item The sequence of iterates does not terminate and remains in a closed, bounded, convex set $D$ on which the function $f$ is twice continuously differentiable and in which $f$ has a unique stationary point $x^*$, i.e. $\nabla f(x^*) = 0$. The Hessian $\nabla^2 f(x^*)$ is positive definite, and $\nabla^2 f(x)$ is Lipschitz continuous in a neighborhood of $x^*$; that is, there exists a constant $\gamma > 0$ such that for all $x, y$ in some neighborhood of $x^*$ \begin{equation*} \lVert \nabla^2 f(x) - \nabla^2 f(y) \rVert_2 \geq \gamma \ \lVert x - y \rVert. \end{equation*}
        \item The sequence of matrices $\{ H^{\mathrm{SR1}}_k \}_k$ is bounded by a constant $M$ such that $\lVert H^{\mathrm{SR1}}_k \rVert_2 \leq M$ for all $k$.
    \end{enumerate}
\end{assumption}
With these assumptions, the following can be shown: 
\begin{theorem}[{\cite[Theorem~2.1.]{ByrdKhalfanSchnabel:1996}}] \label{GlobalConvergence}
    If the sequence $\{ x_k \}_k$ is generated by \cref{TR-SR1Method} and \cref{AssumptionsGlobalConvergence} holds, then $x_k \rightarrow x^*$.
\end{theorem}
In \cite{ConnGouldToint:1991} it was proven that the sequence of matrices $\{ H^{\mathrm{SR1}}_k \}_k$ generated by \cref{directSR1formula} converges to the actual Hessian at the solution $\nabla^2 f(x^*)$, provided that the sequence of steps taken $\{ s_k \}_k$ is uniformly linearly independent, that the denominator in \cref{directSR1formula} is sufficiently different from zero, and that the iterates $\{ x_k \}_k$ converge to $x^*$. Using this result it is simple to prove that the convergence rate of \cref{TR-SR1Method} under these unusual and strong assumptions is q-superlinear \cite[p.~1026]{ByrdKhalfanSchnabel:1996}. \\
The $n+1$-step q-superlinear rate of convergence of the \cref{TR-SR1Method} was shown under fairly mild assumptions in \cite{ByrdKhalfanSchnabel:1996} using a sophisticated analysis that builds on \cite{ConnGouldToint:1991} and \cite{KhalfanByrdSchnabel:1993}. The following additional assumption is needed: 
\begin{assumption}[{\cite[(A2)]{ByrdKhalfanSchnabel:1996}}]\label{AssumptionsLocalConvergence}
    The sequence of matrices $\{ H^{\mathrm{SR1}}_k \}_k$ is generated from each iterate $x_k$ by \cref{directSR1formula}, using $s_k$, and for each iteration \cref{safeguard} holds, where $r \in (0, 1)$ is a constant.
\end{assumption}
\begin{theorem}[{\cite[Theorem~2.7.]{ByrdKhalfanSchnabel:1996}}] \label{LocalConvergence}
    Consider \cref{TR-SR1Method} satisfying \cref{accuracy1} and \cref{accuracy1} and suppose that \cref{AssumptionsGlobalConvergence} and \cref{AssumptionsLocalConvergence} hold. Then the sequence $\{ x_k \}_k$ generated by \cref{TR-SR1Method} converges $n+l$-step superlinear, i.e. 
    \begin{equation}\label{n+1superlinear}
        \lim_{k \rightarrow \infty} \frac{\lVert x_{k+n+1} - x^* \rVert}{\lVert x_k - x^* \rVert} = 0.
    \end{equation}
\end{theorem}
This result is very interesting because it can be argued that the concept of Trust-Region methods is appropriate for the Symmetric Rank-One update \cite[p.~1025]{ByrdKhalfanSchnabel:1996}.
