\chapter{Euclidean Trust-Region Symmetric Rank-One Method}

In the Euclidean optimization a key problem is minimizing a real-valued function $f$ over the Euclidean space $\mathbb{R}^n$ ($n \geq 1$), i.e. our focus and efforts are centred on solving 
\begin{equation}\label{OptimizationProblem}
    \min f(x), \quad x \in \mathbb{R}^n
\end{equation}  
where $f \colon \; \mathbb{R}^n \to \mathbb{R}$ is a smooth function. In this chapter we focus on smooth functions, by which we generally mean functions whose second derivatives exist and are continuous or formally $f \in C^2(\mathbb{R}^n)$, unless otherwise stated. \cref{OptimizationProblem} is called a (nonlinear) unconstrained optimization problem. \\
The Trust-region method is one of the most important numerical optimization methods in solving \cref{OptimizationProblem}. At each iterate $x_k$, we first define a qudratic model 
\begin{equation}\label{QudraticModel}
    m_k(s) = f(x_k) + \nabla f(x_k)^{\mathrm{T}} s + \frac{1}{2} s^{\mathrm{T}} H_k s,
\end{equation}
where $\nabla f(x_k)$ denotes the gradient of the objective function $f$ at the current iterate $x_k$ and $H_k \in  \mathbb{R}^{n \times n}$ is a symmetric matrix. The difference between \cref{QudraticModel} and the objective function is $\mathcal{O}(\lVert s \rVert^{2}_2)$, which is small when $\lVert s \rVert_2$ is small. If $H_k$ is equal to the true Hessian $\nabla^2 f(x_k)$ at the current iterate, the approximation error in the model $m_k$ is $\mathcal{O}(\lVert s \rVert^{3}_2)$, so this model is especially accurate when $\lVert s \rVert_2$ is small. This choice $H_k = \nabla^2 f(x_k)$ leads to the trust-region Newton method \cite[p.~68]{NocedalWright:2006}. \\
Nevertheless, the model \cref{QudraticModel} is easier to handle than the objective function $f$ and its purpose is to approximate $f$ within a suitable neighbourhood of the current iterate $x_k$, which we refer to as the trust-region. The trust-region is the set of all points
\begin{equation}\label{TrustRegion}
    \{ x \in \mathbb{R}^n \colon \ \lVert x - x_k \rVert_2 \leq \Delta_k \}
\end{equation}
where $\Delta_k > 0$ is the trust-region radius \cite[p.~115]{ConnGouldToint:2000}. The region \cref{TrustRegion} is so called because we trust the model \cref{QudraticModel} to be a faithful representation of the objective function only in this region \cite[p.~2]{ConnGouldToint:2000}. \\
Given the model \cref{QudraticModel} and its trust-region \cref{TrustRegion}, we next seek a step $s_k$ with the aim of reducing the model \cref{QudraticModel} while satisfying the bound $\lVert s_k \rVert_2 \leq \Delta_k$, this means in each iteration we compute the minimizer of the so-called Trust-region subproblem
\begin{equation}\label{trsubproblem}
    s_k = \arg \min_{\lVert s \rVert_2 \leq \Delta_k} m_k(s) = \arg \min_{\lVert s \rVert_2 \leq \Delta_k} f(x_k) + \nabla f(x_k)^{\mathrm{T}} s + \frac{1}{2} s^{\mathrm{T}} H_k s.
\end{equation}
In general, the step $s_k$ is just a approximate solution to \cref{trsubproblem}, which is required to be accurate enough that for all $k$
\begin{equation}\label{accuracy1}
    -(\nabla f(x_k)^{\mathrm{T}} s + \frac{1}{2} s^{\mathrm{T}} H_k s) \geq \sigma_1 \ \lVert \nabla f(x_k) \rVert \ \min \{ \Delta_k, \sigma_2 \ \frac{\lVert \nabla f(x_k) \rVert}{\lVert H_k \rVert} \} 
\end{equation} 
for positive constants $\sigma_1$ and $\sigma_2$ and such that 
\begin{equation}\label{accuracy2}
    \text{whenever } \lVert s_k \rVert < 0.8 \ \Delta_k, \text{ then } H_k s_k = - \nabla f(x_k).
\end{equation}
These conditions are satisfied if \cref{trsubproblem} is solved exactly and are satisfied by most approximate trust-region strategies that are used in practice \cite[p.~1027]{ByrdKhalfanSchnabel:1996}. A standard method for this is the so-called truncated conjugate-gradient method, which is an “inverse-free” algorithm, as it only uses $H_k$, that achieves at least as much reduction in the model $m_k$ as the reduction achieved by the so-called Cauchy point (see \cite[4.1~Algorithms~based~on~the~cauchy~point]{NocedalWright:2006}). This point is simply the minimizer of $m_k$ along the steepest descent direction $- \nabla f(x_k)$ subject to the trust-region bound \cite[p.~71]{NocedalWright:2006}. \\
Having determined the step $s_k$, we get the candidate for the next iterate by adding it to the current iterate $x_k$, i.e. we compute 
\begin{equation}\label{candidate}
    \widetilde{x}_{k+1} = x_k + s_k.
\end{equation}
We are only talking about a candidate because we make the acceptance of $\widetilde{x}_{k+1}$ as the next iterate $x_{k+1}$ dependent on the agreement between the objective function $f$ and the quadratic model $m_k$ for the step $s_k$. For that we compute at each iteration the value
\begin{equation}\label{agreement}
    \rho_k = \frac{f(x_k) - f(x_k + s_k)}{m_k(0) - m_k(s_k)} = \frac{f(x_k) - f(\widetilde{x}_{k+1})}{m_k(0) - m_k(s_k)},
\end{equation}
the numerator is called the actual reduction, and the denominator is the predicted reduction (that is, the reduction in $f$ predicted by the model $m_k$). We point out that since the step $s_k$ is obtained by minimizing the model $m_k$ over a region that includes $s = 0$, the predicted reduction will always be nonnegative. Hence, if $\rho_k$ is negative, the new objective value $f(x_k + s_k)$ is greater than the current value $f(x_k)$, so the step must be rejected \cite[p.~68-69]{NocedalWright:2006}. In general, the candidate $\widetilde{x}_{k+1}$ is accepted as the next iterate $x_{k+1}$ if $\rho_k$ is greater than a chosen constant $\rho^{\prime} \in [0 , \frac{1}{4})$. \\
At the end of each iteration, the trust-region radius $\Delta_k$ is updated. There are diverse heuristics for this, which in general base this choice on $\rho_k$ and the norm of the step $s_k$. We consider the strategy of downsizing the trust-region radius, i.e. $\Delta_{k+1} < \Delta_k$, if $\rho_k$ is less than $0.1$, which indicates that the model $m_k$ in the current trust-region poorly represents the objective function $f$, and increasing the trust-region radius, i.e. $\Delta_{k+1} > \Delta_k$, if $\rho_k$ is greater than $0.75$ and the norm of $s_k$ is greater than or equal to $0.8 \ \Delta_k$, indicating that the model $m_k$ represents the objective function $f$ well enough in the current trust-region and and the current step $s_k$ is pretty close to the boundary of the current trust-region. \\
The size of the trust-region is critical to the effectiveness of each step. If the region is too small, the algorithm misses an opportunity to take a substantial step that will move it much closer to the minimizer of the objective function. If too large, the minimizer of the model may be far from the minimizer of the objective function in the region, so we may have to reduce the size of the region and try again. In general, the direction of the step changes whenever the size of the trust-region is altered. \cite[p.~67]{NocedalWright:2006}. \\

Let us now turn to the convergence results that can be achieved by this class of numerical methods. These depend (among other things) on the quadratic term $H_k$ in our model $m_k$. As already mentioned, a possible choice would be the Hessian matrix, i.e. $H_k = \nabla^2 f(x_k)$. If the iterates $\{ x_k \}_k$ generated by the rsulting algorithm converge to a point $x^*$ satisfying second-order sufficient conditions, it can be shown that the rate of convergence is superlinear (see \cite[4.4~Local~convergence~of~trust-region~Newton~methods]{NocedalWright:2006}). \\
But in practice there are cases where the Hessian matrix of the objective function is too costly to calculate, or even does not exist at all. Therefore, one is interested in an approximation of the second derivative of the objective function, and there are various approaches for this. \\
If one considers Euclidean line search methods, then the so-called quasi-Newton methods provide a promising approach. These methods are based on Newton's method, which means that they also want to minimise the model of the objective function, but now without the restriction of the trust-region, and consequently obtain the search direction $s_k$ by solving the linear system of equations $H_k s_k = - \nabla f(x_k)$. Here the matrix $H_k \in \mathbb{R}^{n \times n}$ approximates the action of the objective's Hessian $\nabla^{2} f(x_k)$ at the current iterate in the direction of $s_k$. After the next iterate in this class of line search methods is calculated, i.e. $x_{k+1} = x_k + \alpha_k s_k$ ($\alpha_k$ is the step size calculated in the meantime), this matrix $H_k$ is not calculated anew in each iteration, but $H_k$ is updated to a new matrix $H_{k+1} \in \mathbb{R}^{n \times n}$ using the information about the curvature of the objective function $f$ obtained by the difference of the iterates, which is given by the step $s_k = x_{k+1} - x_k \in \mathbb{R}^n$, and the difference of the gradients at the iterates, which we denote by $y_k = \nabla f(x_{k+1}) - \nabla f(x_k) \in \mathbb{R}^n$. It is required that the new matrix $H_{k+1}$ generated by the update fulfills the so-called quasi-Newton equation, which reads as 
\begin{equation}\label{quasi-NewtonEquation}
    H_{k+1} (x_{k+1} - x_k) = \nabla f(x_{k+1}) - \nabla f(x_k) \text{ or } H_{k+1} s_k = y_k.
\end{equation}
The fact that the matrix $H_{k+1}$ satisfies the quasi-Newton equation, \cref{quasi-NewtonEquation}, is the distinguishing feature of quasi-Newton methods. \\

But there is also a simpler rank-one update that maintains symmetry of the matrix $H_k$ or $B_k$ and satisfies the quasi-Newton equation \cref{quasi-NewtonEquation}. Unlike the rank-two BFGS update, this symmetric rank-one, or short SR1, update does not guarantee that the updated matrix $H_{k+1}$ or $B_{k+1}$ maintains positive definiteness. Nevertheless good numerical results have been obtained with algorithms based on SR1, therefore we now show a possible derivation of this formula, which is so simple that it has been rediscovered a number of times. \\


The idea now is to find a convenient formula, for updating the matrix $H_k$ to a new matrix $H_{k+1}$, which satisfies the quasi-Newton equation \cref{quasi-NewtonEquation}. Instead of recomputing $H_{k+1}$ from scratch at every iteration, we apply a simple modification that combines the most recently observed information about the objective function with the existing knowledge embedded in $H_k$ or $B_k$ \cite[p.~139]{NocedalWright:2006}. 



But there is also a simpler rank-one update that maintains symmetry of the matrix $H_k$ or $B_k$ and satisfies the quasi-Newton equation \cref{quasi-NewtonEquation}. Unlike the rank-two BFGS update, this symmetric rank-one, or short SR1, update does not guarantee that the updated matrix $H_{k+1}$ or $B_{k+1}$ maintains positive definiteness. Nevertheless good numerical results have been obtained with algorithms based on SR1, therefore we now show a possible derivation of this formula, which is so simple that it has been rediscovered a number of times. \\
A general symmetric rank-one update has the form
\begin{equation*}
    H_{k+1} = H_k + \sigma \, v v^{\mathrm{T}},
\end{equation*}
where $v \in \mathbb{R}^n$ and $\sigma \in \{-1,1\}$. The task now is to determine $v$ and $\sigma$ so that $H_{k+1}$ satisfies the quasi-Newton equation, \cref{quasi-NewtonEquation}. By substituting into \cref{quasi-NewtonEquation}, we obtain
\begin{equation}\label{Derivation1}
    H_k s_k + [\sigma \, v^{\mathrm{T}} s_k] v = y_k.
\end{equation}
Since $[\sigma \, v^{\mathrm{T}} s_k]$ is a scalar, $v$ must be a multiple of $y_k − H_k s_k$, i.e. $v = \delta (y_k − H_k s_k)$ for some $\delta \in \mathbb{R}$. By substituting this form of $v$ into \cref{Derivation1}, we obtain
\begin{equation}\label{Derivation2}
    (y_k − H_k s_k) = \sigma \, \delta^2 \, [s^{\mathrm{T}}_k (y_k − H_k s_k)](y_k − H_k s_k),
\end{equation}
and it is clear that this equation is satisfied if (and only if) we choose the parameters $\delta$ and $\sigma$ to be
\begin{equation*}
    \sigma = \operatorname{sgn} (s^{\mathrm{T}}_k (y_k − H_k s_k)), \quad \delta = \pm \lvert s^{\mathrm{T}}_k (y_k − H_k s_k) \rvert^{-\frac{1}{2}}.
\end{equation*}
Hence, the only symmetric rank-one update formula that satisfies the quasi-Newton equation, \cref{quasi-NewtonEquation}, is given by
\begin{equation}\label{directSR1formula}
    H^\mathrm{SR1}_{k+1} = H^\mathrm{SR1}_k + \frac{(y_k - H^\mathrm{SR1}_k s_k) (y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}}}{(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k}.
\end{equation}

It is easy to see in that even if $H^\mathrm{SR1}_k$ is positive definite, $H^\mathrm{SR1}_{k+1}$ may not have the same property (this holds also for $B^\mathrm{SR1}_k$ and $B^\mathrm{SR1}_{k+1}$). If and only if $(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k > 0$, the SR1 update retains positive definiteness. However, this condition is difficult to guarantee. This means that $H^\mathrm{SR1}_{k+1}$ or $B^\mathrm{SR1}_{k+1}$ may no longer be invertible. Moreover, $d_{k+1} = -{H^\mathrm{SR1}_{k+1}}^{-1} \nabla f(x_{k+1}) = -B^\mathrm{SR1}_{k+1} \nabla f(x_{k+1})$ is not necessarily a descent direction. \\


The main drawback of the SR1 update formula is that the denominator in \cref{directSR1formula} can vanish. In fact, even when the objective function $f$ is convex and quadratic, there may be steps on which there is no symmetric rank-one update that satisfies the quasi-Newton equation \cref{quasi-NewtonEquation}. This disadvantage results in serious numerical difficulties, which restrict the applications of it. Nevertheless, the SR1 update formula has the following advantages:


For the vanishing denominator in \cref{directSR1formula} we introduce a strategy to prevent a method using the SR1 update from breaking down. It has been observed in practice that it performs well simply by skipping the update if the denominator is small. More specifically, the update \cref{directSR1formula} is applied only if 
\begin{equation}\label{safeguard}
    \lvert (y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k \lvert \; \geq \; \nu \; \lVert s_k \rVert \lVert y_k - H^\mathrm{SR1}_k s_k \rVert 
\end{equation}
holds, where $\nu \in (0, 1)$ is a small number, e.g. $r = 10^{−8}$. Most implementations of the SR1 update use a skipping rule of this kind. The condition $(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k \approx 0$ occurs infrequently, since it requires certain vectors to be aligned in a specific way. When it occurs, skipping the update appears to have no negative effects on the iteration, since the skipping condition implies that $s^{\mathrm{T}}_k \tilde{G} s_k \approx s^{\mathrm{T}}_k H^\mathrm{SR1}_k s_k$, where $\tilde{G}$ is the average Hessian over the last step, meaning that the curvature of $H^\mathrm{SR1}_k$ along $s_k$ is already correct. \\







\begin{algorithm}[H]
    \caption{Trust-Region Symmetric Rank-One Method}\label{TR-SR1Method}
    \begin{algorithmic}[1]
        \State Continuously differentiable real-valued function $f$ on $\mathbb{R}^n$, bounded below; initial iterate $x_0 \in \mathbb{R}^n$; initial $\spd$ matrix $H^{\mathrm{SR1}}_0 \in \mathbb{R}^{n \times n}$; initial trust-region radius $\Delta_0 > 0$; safeguard constant $\nu \in (0,1)$; rejection boundary $\rho^{\prime} \in (0, 0.1)$; trust-region reduction factor $\tau_1 \in (0,1)$; trust-region magnification factor $\tau_2 > 1$; convergence tolerance $\varepsilon > 0$. Set $k = 0$.
        \While{$\lVert \nabla f(x_k) \rVert > \varepsilon$}
            \State Obtain $s_k$ (approximately) solving \cref{trsubproblem}.
            \State Set $\widetilde{x}_{k+1} = x_k + s_k$ and $y_k = \nabla f(\widetilde{x}_{k+1}) - \nabla f(x_k)$.
            \If{\cref{safeguard} holds}
                \State Compute $H^{\mathrm{SR1}}_{k+1} \in \mathbb{R}^{n \times n}$ by means of \cref{directSR1formula}.
			\Else 
				\State Set $H^{\mathrm{SR1}}_{k+1} = H^{\mathrm{SR1}}_k$.
            \EndIf 
            \State Compute $\rho_k = \frac{f(x_k) - f(\widetilde{x}_{k+1})}{m_k(0) - m_k(s_k)}$.
            \If{$\rho_k > \rho^{\prime}$}
                \State Set $x_{k+1} = \widetilde{x}_{k+1}$.
			\Else 
				\State Set $x_{k+1} = x_k$.
            \EndIf 
            \If{$\rho_k > 0.75$}
                \If{$\lVert s_k \rVert_2 \geq 0.8 \ \Delta_k$}
                    \State Set $\Delta_{k+1} = \tau_2 \ \Delta_k$.
                \Else 
                    \State Set $\Delta_{k+1} = \Delta_k$.
                \EndIf 
			\Else 
                \If{$\rho_k < 0.1$}
                    \State Set $\Delta_{k+1} = \tau_1 \ \Delta_k$.
                \Else 
                    \State Set $\Delta_{k+1} = \Delta_k$.
                \EndIf 
            \EndIf 
            \State Set $k = k+1$.
        \EndWhile
        \State \textbf{Return} $x_k$.
    \end{algorithmic}
\end{algorithm}

The SR1 update has been shown to be very effective in optimization calculations, especially when used in conjunction with a trust-region method. The theoretical understanding of its Convergence behavior on nonquadratic problems is still rather incomplete, however. Minimization algorithms using this update in both a line search and a trust-region context have been shown in computational experiments by Conn, Gould, and Toint and by to be competitive with methods using the widely accepted Broyden-Fletcher-Goldfarb-Shanno (BFGS) update. The convergence of such algorithms is not as well understood, however, as convergence of the BFGS method. A significant difference between the BFGS and SR1 updates that contributes to this situation is that although the BFGS algorithm is guaranteed to produce a positive definite $H^{BFGS}_{k+1}$ if $H^{BFGS}_k$ is positive definite and $s^{\mathrm{T}}_k y_k > 0$ holds, the SR1 update does not have this property. In practical implementations of an SR1 method, the Hessian approximations $H^{SR1}_k$ may be indefinite at some iterations. \cite[p.~1025-1026]{ByrdKhalfanSchnabel:1996}. 

The paper by \cite{ByrdKhalfanSchnabel:1996} provides a local convergence analysis of a trust-region, SR1 method for unconstrained optimization under fairly mild assumptions. 

\begin{assumption}[{\cite[assumptions~(A1)+(A3)]{ByrdKhalfanSchnabel:1996}}]\label{AssumptionsGlobalConvergence} \ \\[-1.5\baselineskip]
    \begin{enumerate}
        \item The sequence of iterates does not terminate and remains in a closed, bounded, convex set $D$ on which the function $f$ is twice continuously differentiable and in which $f$ has a unique stationary point $x^*$, i.e. $\nabla f(x^*) = 0$. The Hessian $\nabla^2 f(x^*)$ is positive definite, and $\nabla^2 f(x)$ is Lipschitz continuous in a neighborhood of $x^*$; that is, there exists a constant $\gamma > 0$ such that for all $x, y$ in some neighborhood of $x^*$ \begin{equation*} \lVert \nabla^2 f(x) - \nabla^2 f(y) \rVert \geq \gamma \ \lVert x - y \rVert. \end{equation*}
        \item The sequence of matrices $\{ H^{\mathrm{SR1}}_k \}_k$ is bounded by a constant $M$ such that $\lVert H^{\mathrm{SR1}}_k \rVert \leq M$ for all $k$.
    \end{enumerate}
\end{assumption}

\begin{theorem}[{\cite[Theorem~2.1.]{ByrdKhalfanSchnabel:1996}}] \label{GlobalConvergence}
    If the sequence $\{ x_k \}_k$ is generated by \cref{TR-SR1Method} and \cref{AssumptionsGlobalConvergence} holds, then $x_k \rightarrow x^*$.
\end{theorem}

Conn, Gould, and Toint proved that the sequence of matrices generated by the SR1 formula converges to the actual Hessian at the solution $\nabla^2 f(x^*)$, provided that the sequence of steps taken, $\{ s_k \}_k$, is uniformly linearly independent, that the denominator in (1.2) is sufficiently different from zero, and that the iterates converge to $x^*$. Using this result it is simple to prove that the rate of convergence under these assumptions is q-superlinear. (Interestingly, for the BFGS method Ge and Powell proved, under a different set of assumptions, that the sequence of generated matrices converges but not necessarily to $\nabla^2 f(x^*)$.) The assumption of uniform linear independence is unusual and fairly strong, but Conn, Gould, and Toint present experiments on minimization of randomly generated quartics in which it holds. On the other hand, experiments by Khalfan, Byrd, and Schnabel [1993] showed that nearly dependent steps occurred commonly when using the SR1 in both a line search and a trust-region method on a standard set of unconstrained optimization test problems \cite[p.~1026]{ByrdKhalfanSchnabel:1996}.


\begin{assumption}[{\cite[assumptions~(A1)+(A3)]{ByrdKhalfanSchnabel:1996}}]\label{AssumptionsLocalConvergence} \ \\[-1.5\baselineskip]
    \begin{enumerate}
        \item The sequence of matrices $\{ H^{\mathrm{SR1}}_k \}_k$ is generated from each iterate $x_k$ by \cref{directSR1formula}, using $s_k$, and for each iteration \cref{safeguard} holds, where $\nu \in (0, 1)$ is a constant.
        \item The trust-region subproblem \cref{trsubproblem} is solved accurately enough that for all $k$ \begin{equation*} -(\nabla f(x_k)^{\mathrm{T}} s + \frac{1}{2} s^{\mathrm{T}} H^{\mathrm{SR1}}_k s) \geq \sigma_1 \ \lVert \nabla f(x_k) \rVert \ \min \{ \Delta_k, \sigma_2 \ \frac{\lVert \nabla f(x_k) \rVert}{\lVert H^{\mathrm{SR1}}_k \rVert} \} \end{equation*} for positive constants $\sigma_1$ and $\sigma_2$ and such that whenever $\lVert s_k \rVert < 0.8 \ \Delta_k$, then $H^{\mathrm{SR1}}_k s_k = - \nabla f(x_k)$.
    \end{enumerate}
\end{assumption}

\begin{theorem}[{\cite[Theorem~2.7.]{ByrdKhalfanSchnabel:1996}}] \label{LocalConvergence}
    Consider \cref{TR-SR1Method} and suppose that \cref{AssumptionsGlobalConvergence} and \cref{AssumptionsLocalConvergence} hold. Then the sequence $\{ x_k \}_k$ generated by \cref{TR-SR1Method} converges $n+l$-step superlinear, i.e. 
    \begin{equation}\label{n+1superlinear}
        \lim_{k \rightarrow \infty} \frac{\lVert x_{k+n+1} - x^* \rVert}{\lVert x_k - x^* \rVert} = 0.
    \end{equation}
\end{theorem}

The new results are particularly interesting, first because a trust-region method can be argued to be the appropriate context for the SR1 and second because the trust-region .structure allows some of the less desirable assumptions made by Khalfan, Byrd, and Schnabel [1993] in analyzing the SR1 for a line search method to be relaxed. In particular, no assumption about the positive definiteness of the Hessian approximations is made \cite[p.~1025]{ByrdKhalfanSchnabel:1996}.
