\chapter{Euclidean Trust-Region Symmetric Rank-One Method}

In the Euclidean optimization a key problem is minimizing a real-valued function $f$ over the Euclidean space $\mathbb{R}^n$ ($n \geq 1$), i.e. our focus and efforts are centred on solving 
\begin{equation}\label{OptimizationProblem}
    \min f(x), \quad x \in \mathbb{R}^n
\end{equation}  
where $f \colon \; \mathbb{R}^n \to \mathbb{R}$ is a smooth function. In this chapter we focus on smooth functions, by which we generally mean functions whose second derivatives exist and are continuous or formally $f \in C^2(\mathbb{R}^n)$, unless otherwise stated. \cref{OptimizationProblem} is called a (nonlinear) unconstrained optimization problem. \\
The Trust-region method is one of the most important numerical optimization methods in solving \cref{OptimizationProblem}. At each iterate $x_k$, we first define a qudratic model 
\begin{equation}\label{QudraticModel}
    m_k(s) = f(x_k) + \nabla f(x_k)^{\mathrm{T}} s + \frac{1}{2} s^{\mathrm{T}} H_k s,
\end{equation}
where $\nabla f(x_k)$ denotes the gradient of the objective function $f$ at the current iterate $x_k$ and $H_k \in  \mathbb{R}^{n \times n}$ is a symmetric matrix. The difference between \cref{QudraticModel} and the objective function is $\mathcal{O}(\lVert s \rVert^{2}_2)$, which is small when $\lVert s \rVert_2$ is small. If $H_k$ is equal to the true Hessian $\nabla^2 f(x_k)$ at the current iterate, the approximation error in the model $m_k$ is $\mathcal{O}(\lVert s \rVert^{3}_2)$, so this model is especially accurate when $\lVert s \rVert_2$ is small. This choice $H_k = \nabla^2 f(x_k)$ leads to the trust-region Newton method \cite[p.~68]{NocedalWright:2006}. \\
Nevertheless, the model \cref{QudraticModel} is easier to handle than the objective function $f$ and its purpose is to approximate $f$ within a suitable neighbourhood of the current iterate $x_k$, which we refer to as the trust-region. The trust-region is the set of all points
\begin{equation}\label{TrustRegion}
    \{ x \in \mathbb{R}^n \colon \ \lVert x - x_k \rVert_2 \leq \Delta_k \}
\end{equation}
where $\Delta_k > 0$ is the trust-region radius \cite[p.~115]{ConnGouldToint:2000}. The region \cref{TrustRegion} is so called because we trust the model \cref{QudraticModel} to be a faithful representation of the objective function only in this region \cite[p.~2]{ConnGouldToint:2000}. \\
Given the model \cref{QudraticModel} and its trust-region \cref{TrustRegion}, we next seek a step $s_k$ with the aim of reducing the model \cref{QudraticModel} while satisfying the bound $\lVert s_k \rVert_2 \leq \Delta_k$, this means in each iteration we compute the minimizer of the so-called Trust-region subproblem
\begin{equation}\label{trsubproblem}
    s_k = \arg \min_{\lVert s \rVert_2 \leq \Delta_k} m_k(s) = \arg \min_{\lVert s \rVert_2 \leq \Delta_k} f(x_k) + \nabla f(x_k)^{\mathrm{T}} s + \frac{1}{2} s^{\mathrm{T}} H_k s.
\end{equation}
In general, the step $s_k$ is just a approximate solution to \cref{trsubproblem}, which is required to be accurate enough that for all $k$
\begin{equation}\label{accuracy1}
    m_k(0) - m_k(s_k) \geq \sigma_1 \ \lVert \nabla f(x_k) \rVert \ \min \{ \Delta_k, \sigma_2 \ \frac{\lVert \nabla f(x_k) \rVert}{\lVert H_k \rVert} \} 
\end{equation} 
for positive constants $\sigma_1$ and $\sigma_2$ and such that 
\begin{equation}\label{accuracy2}
    \text{whenever } \lVert s_k \rVert < 0.8 \ \Delta_k, \text{ then } H_k s_k = - \nabla f(x_k).
\end{equation}
These conditions are satisfied if \cref{trsubproblem} is solved exactly and are satisfied by most approximate trust-region strategies that are used in practice \cite[p.~1027]{ByrdKhalfanSchnabel:1996}. A standard method for this is the so-called truncated conjugate-gradient method, which is an “inverse-free” algorithm, as it only uses $H_k$, that achieves at least as much reduction in the model $m_k$ as the reduction achieved by the so-called Cauchy point (see \cite[4.1~Algorithms~based~on~the~cauchy~point]{NocedalWright:2006}). This point is simply the minimizer of $m_k$ along the steepest descent direction $- \nabla f(x_k)$ subject to the trust-region bound \cite[p.~71]{NocedalWright:2006}. \\
Having determined the step $s_k$, we get the candidate for the next iterate by adding it to the current iterate $x_k$, i.e. we compute 
\begin{equation}\label{candidate}
    \widetilde{x}_{k+1} = x_k + s_k.
\end{equation}
We are only talking about a candidate because we make the acceptance of $\widetilde{x}_{k+1}$ as the next iterate $x_{k+1}$ dependent on the agreement between the objective function $f$ and the quadratic model $m_k$ for the step $s_k$. For that we compute at each iteration the value
\begin{equation}\label{agreement}
    \rho_k = \frac{f(x_k) - f(x_k + s_k)}{m_k(0) - m_k(s_k)} = \frac{f(x_k) - f(\widetilde{x}_{k+1})}{m_k(0) - m_k(s_k)},
\end{equation}
the numerator is called the actual reduction, and the denominator is the predicted reduction (that is, the reduction in $f$ predicted by the model $m_k$). We point out that since the step $s_k$ is obtained by minimizing the model $m_k$ over a region that includes $s = 0$, the predicted reduction will always be nonnegative. Hence, if $\rho_k$ is negative, the new objective value $f(x_k + s_k)$ is greater than the current value $f(x_k)$, so the step must be rejected \cite[p.~68-69]{NocedalWright:2006}. In general, the candidate $\widetilde{x}_{k+1}$ is accepted as the next iterate $x_{k+1}$ if $\rho_k$ is greater than a chosen constant $\rho^{\prime} \in [0 , \frac{1}{4})$. \\
At the end of each iteration, the trust-region radius $\Delta_k$ is updated. There are diverse heuristics for this, which in general base this choice on $\rho_k$ and the norm of the step $s_k$. We consider the strategy of downsizing the trust-region radius, i.e. $\Delta_{k+1} < \Delta_k$, if $\rho_k$ is less than $0.1$, which indicates that the model $m_k$ inside the current trust-region poorly represents the objective function $f$, and increasing the trust-region radius, i.e. $\Delta_{k+1} > \Delta_k$, if $\rho_k$ is greater than $0.75$ and the norm of $s_k$ is greater than or equal to $0.8 \ \Delta_k$, indicating that the model $m_k$ represents the objective function $f$ well enough inside the current trust-region and and the current step $s_k$ is pretty close to the boundary of the current trust-region. \\
The size of the trust-region is critical to the effectiveness of each step. If the region is too small, the algorithm misses an opportunity to take a substantial step that will move it much closer to the minimizer of the objective function. If too large, the minimizer of the model may be far from the minimizer of the objective function in the region, so we may have to reduce the size of the region and try again. In general, the direction of the step changes whenever the size of the trust-region is altered. \cite[p.~67]{NocedalWright:2006}. \\

The convergence results depend (among other things) on the quadratic term $H_k$ in our model $m_k$. As already mentioned, a possible choice would be the Hessian matrix, i.e. $H_k = \nabla^2 f(x_k)$. If the iterates $\{ x_k \}_k$ generated by the rsulting algorithm converge to a point $x^*$ satisfying second-order sufficient conditions, it can be shown that the rate of convergence is superlinear (see \cite[4.4~Local~convergence~of~trust-region~Newton~methods]{NocedalWright:2006}). \\
But in practice there are cases where the Hessian matrix of the objective function is too costly to calculate, or even does not exist at all. Therefore, one is interested in an approximation of the second derivative of the objective function, and there are various approaches for this. \\
If one considers Euclidean linesearch methods, then the so-called quasi-Newton methods provide a promising approach. These methods are based on Newton's method, which means that they also want to minimize the model of the objective function, but now without the restriction of the trust-region, and consequently obtain the search direction $d_k$ by solving the linear system of equations $H_k d_k = - \nabla f(x_k)$. Here the matrix $H_k \in \mathbb{R}^{n \times n}$ approximates the action of the objective's Hessian $\nabla^{2} f(x_k)$ at the current iterate. After the next iterate is calculated, i.e. $x_{k+1} = x_k + \alpha_k d_k$ ($\alpha_k$ is the step size calculated in the meantime), this matrix $H_k$ is not calculated anew in each iteration, but $H_k$ is updated to a new matrix $H_{k+1} \in \mathbb{R}^{n \times n}$ using the information about the curvature of the objective function $f$ obtained by the difference of the iterates, which we denote by $s_k = x_{k+1} - x_k = \alpha_k d_k \in \mathbb{R}^n$, and by the difference of the gradients at the iterates, which we denote by $y_k = \nabla f(x_{k+1}) - \nabla f(x_k) \in \mathbb{R}^n$. It is required that the new matrix $H_{k+1}$ generated by the update fulfills the so-called quasi-Newton equation, which reads as 
\begin{equation}\label{quasi-NewtonEquation}
    H_{k+1} (x_{k+1} - x_k) = \nabla f(x_{k+1}) - \nabla f(x_k) \quad \text{or} \quad H_{k+1} s_k = y_k,
\end{equation}
since one expects good approximation properties by fulfillment. The fact that the matrix $H_{k+1}$ satisfies the quasi-Newton equation, \cref{quasi-NewtonEquation}, is the distinguishing feature of quasi-Newton methods. \\

There are several update formulae that satisfy the quasi-Newton equation \cref{quasi-NewtonEquation} and even produce a symmetric positive definite matrix $H_{k+1}$ under additional assumptions, which is attractive for linesearch methods, since the search direction $s_k$ thus generated is a descent direction (i.e. $\nabla f(x_k)^{\mathrm{T}} s_k < 0$). These formulas are characterized by the fact that they are so-called rank-two updates, since they add to the current matrix $H_k$ a matrix with rank 2, which obtains the information about the curvature of the objective function. \\
But there is also a simpler rank-one update that maintains symmetry of the matrix $H_k$ and satisfies the quasi-Newton equation \cref{quasi-NewtonEquation}. Unlike the rank-two updates, this symmetric rank-one, or short SR1, update does not guarantee that the updated matrix $H_{k+1}$ maintains positive definiteness. Nevertheless good numerical results have been obtained with algorithms based on SR1 update, which is given by
\begin{equation}\label{directSR1formula}
    H^\mathrm{SR1}_{k+1} = H^\mathrm{SR1}_k + \frac{(y_k - H^\mathrm{SR1}_k s_k) (y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}}}{(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k}.
\end{equation}
It is easy to see in that even if $H^\mathrm{SR1}_k$ is positive definite, $H^\mathrm{SR1}_{k+1}$ may not have the same property. If and only if $(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k > 0$, the SR1 update retains positive definiteness. However, this condition is difficult to guarantee. It can be shown, if $(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k \neq 0$ holds, that \cref{directSR1formula} is the unique symmetric rank-one formula, so that $H^\mathrm{SR1}_{k+1}$ satisfies the quasi-Newton equation \cref{quasi-NewtonEquation} \cite[p.~144-145]{NocedalWright:2006}. \\

We need to adjust the definition for the vectors $s_k$ and $y_k$ through which we get information into the matrix $H^\mathrm{SR1}_{k+1}$ so that we can use this update formula for the trust-region approach. The goal is to make the approximation as accurate as possible, which is why in each iteration, regardless of whether we accept or reject the candidate, we update the matrix $H^\mathrm{SR1}_k$ by using information we get also from the candidate. This means that we use the vector $s_k = \widetilde{x}_{k+1} - x_k$, which we get by minimizing the trust-region subproblem (we note that trust-region methods compute the direction and length of the step simultaneously), and the vector $y_k = \nabla f(\widetilde{x}_{k+1}) - \nabla f(x_k)$, which means that the gradient has to be evaluated additionally at the candidate $\widetilde{x}_{k+1}$ in each iteration. \\

The main drawback of the SR1 update formula is that the denominator in \cref{directSR1formula} can vanish. In fact, even when the objective function $f$ is convex and quadratic, there may be steps on which there is no symmetric rank-one update that satisfies the quasi-Newton equation \cref{quasi-NewtonEquation}. This disadvantage results in serious numerical difficulties, which restrict the applications of this update. Nevertheless, the matrices generated by \cref{directSR1formula} tend to be good approximations to the true Hessian matrix \cite[p.~145]{NocedalWright:2006}. \\
For the vanishing denominator in \cref{directSR1formula} we introduce a strategy to prevent the breakdown of the resulting trust-region SR1 method and the occurrence of numerical instabilities. It has been observed in practice that it performs well simply by skipping the update if the denominator is small. More specifically, the update \cref{directSR1formula} is applied only if 
\begin{equation}\label{safeguard}
    \lvert (y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k \lvert \; \geq \; \nu \; \lVert s_k \rVert \lVert y_k - H^\mathrm{SR1}_k s_k \rVert 
\end{equation}
holds, where $\nu \in (0, 1)$ is a small number, e.g. $r = 10^{−8}$. Most implementations of the SR1 update use a skipping rule of this kind. The condition $(y_k - H^\mathrm{SR1}_k s_k)^{\mathrm{T}} s_k \approx 0$ occurs infrequently, since it requires certain vectors to be aligned in a specific way. When it occurs, skipping the update appears to have no negative effects on the iteration, since the skipping condition implies that $s^{\mathrm{T}}_k \tilde{G} s_k \approx s^{\mathrm{T}}_k H^\mathrm{SR1}_k s_k$, where $\tilde{G}$ is the average Hessian over the last step, meaning that the curvature of $H^\mathrm{SR1}_k$ along $s_k$ is already correct. \\

\begin{algorithm}[H]
    \caption{Trust-Region Symmetric Rank-One Method}\label{TR-SR1Method}
    \begin{algorithmic}[1]
        \State Continuously differentiable real-valued function $f$ on $\mathbb{R}^n$, bounded below; initial iterate $x_0 \in \mathbb{R}^n$; initial symmetric matrix $H^{\mathrm{SR1}}_0 \in \mathbb{R}^{n \times n}$; initial trust-region radius $\Delta_0 > 0$; safeguard constant $\nu \in (0,1)$; rejection boundary $\rho^{\prime} \in (0, 0.1)$; trust-region reduction factor $\tau_1 \in (0,1)$; trust-region magnification factor $\tau_2 > 1$; convergence tolerance $\varepsilon > 0$. Set $k = 0$.
        \While{$\lVert \nabla f(x_k) \rVert > \varepsilon$}
            \State Obtain $s_k$ (approximately) solving \cref{trsubproblem}.
            \State Set $\widetilde{x}_{k+1} = x_k + s_k$ and $y_k = \nabla f(\widetilde{x}_{k+1}) - \nabla f(x_k)$.
            \If{\cref{safeguard} holds} \label{SR1ApproxUpdate}
                \State Compute $H^{\mathrm{SR1}}_{k+1} \in \mathbb{R}^{n \times n}$ by means of \cref{directSR1formula}. 
			\Else 
				\State Set $H^{\mathrm{SR1}}_{k+1} = H^{\mathrm{SR1}}_k$.
            \EndIf 
            \State Compute $\rho_k = \frac{f(x_k) - f(\widetilde{x}_{k+1})}{m_k(0) - m_k(s_k)}$.
            \If{$\rho_k > \rho^{\prime}$} \label{SR1IterateUpdate}
                \State Set $x_{k+1} = \widetilde{x}_{k+1}$.
			\Else 
				\State Set $x_{k+1} = x_k$.
            \EndIf 
            \If{$\rho_k > 0.75$} 
                \If{$\lVert s_k \rVert_2 \geq 0.8 \ \Delta_k$}
                    \State Set $\Delta_{k+1} = \tau_2 \ \Delta_k$.
                \Else 
                    \State Set $\Delta_{k+1} = \Delta_k$.
                \EndIf 
			\Else 
                \If{$\rho_k < 0.1$}
                    \State Set $\Delta_{k+1} = \tau_1 \ \Delta_k$.
                \Else 
                    \State Set $\Delta_{k+1} = \Delta_k$.
                \EndIf 
            \EndIf 
            \State Set $k = k+1$.
        \EndWhile
        \State \textbf{Return} $x_k$.
    \end{algorithmic}
\end{algorithm}

We see that the decision to run the update $H^{\mathrm{SR1}}_k \rightarrow H^{\mathrm{SR1}}_{k+1}$ is independent of the decision to accept or reject the candidate $\widetilde{x}_{k+1}$. This is because in order to obtain a fast rate of convergence, it is important for the matrix $H^{\mathrm{SR1}}_k$ to be updated even along a failed direction $s_k$, i.e. $x_{k+1} = x_k$ but $H^{\mathrm{SR1}}_{k+1}$ is generated by \cref{directSR1formula}. Such updates along failed directions seem to be necessary for the convergence analysis because if the approximation of the Hessian is incorrect along such a direction and is not updated, very similar directions could be generated repeatedly later. Such steps would lead to candidates which would be rejected, which in turn would lead to a reduction of the trust-region in these iterations. This could prevent a superlinear step from being taken even though the Hessian approximation is accurate enough, since the trust-region is potentially small enough that it would interfere \cite[p.~1028]{ByrdKhalfanSchnabel:1996}. \\
Before we get to the local convergence analysis, we want to present the main global convergence result, for which the following assumptions are needed:

\begin{assumption}[{\cite[(A1)+(A3)]{ByrdKhalfanSchnabel:1996}}]\label{AssumptionsGlobalConvergence} \ \\[-1.5\baselineskip]
    \begin{enumerate}
        \item The sequence of iterates does not terminate and remains in a closed, bounded, convex set $D$ on which the function $f$ is twice continuously differentiable and in which $f$ has a unique stationary point $x^*$, i.e. $\nabla f(x^*) = 0$. The Hessian $\nabla^2 f(x^*)$ is positive definite, and $\nabla^2 f(x)$ is Lipschitz continuous in a neighborhood of $x^*$; that is, there exists a constant $\gamma > 0$ such that for all $x, y$ in some neighborhood of $x^*$ \begin{equation*} \lVert \nabla^2 f(x) - \nabla^2 f(y) \rVert \geq \gamma \ \lVert x - y \rVert. \end{equation*}
        \item The sequence of matrices $\{ H^{\mathrm{SR1}}_k \}_k$ is bounded by a constant $M$ such that $\lVert H^{\mathrm{SR1}}_k \rVert \leq M$ for all $k$.
    \end{enumerate}
\end{assumption}

Under these assumptions, it was shown in \cite{ByrdKhalfanSchnabel:1996} that \cref{TR-SR1Method} converges globally: 

\begin{theorem}[{\cite[Theorem~2.1.]{ByrdKhalfanSchnabel:1996}}] \label{GlobalConvergence}
    If the sequence $\{ x_k \}_k$ is generated by \cref{TR-SR1Method} and \cref{AssumptionsGlobalConvergence} holds, then $x_k \rightarrow x^*$.
\end{theorem}

In \cite{ConnGouldToint:1991} it was proven that the sequence of matrices $\{ H^{\mathrm{SR1}}_k \}_k$ generated by \cref{directSR1formula} converges to the actual Hessian at the solution $\nabla^2 f(x^*)$, provided that the sequence of steps taken $\{ s_k \}_k$ is uniformly linearly independent, that the denominator in \cref{directSR1formula} is sufficiently different from zero, and that the iterates $\{ x_k \}_k$ converge to $x^*$. Using this result it is simple to prove that the convergence rate of \cref{TR-SR1Method} under these unusual and strong assumptions is q-superlinear \cite[p.~1026]{ByrdKhalfanSchnabel:1996}. \\
The $n+1$-step q-superlinear rate of convergence of the Trust-Region SR1 method \cref{TR-SR1Method} was shown under fairly mild assumptions in \cite{ByrdKhalfanSchnabel:1996} using a sophisticated analysis that builds on \cite{ConnGouldToint:1991} and \cite{KhalfanByrdSchnabel:1993}. For this one still needs the following assumption:

\begin{assumption}[{\cite[(A2)]{ByrdKhalfanSchnabel:1996}}]\label{AssumptionsLocalConvergence}
    The sequence of matrices $\{ H^{\mathrm{SR1}}_k \}_k$ is generated from each iterate $x_k$ by \cref{directSR1formula}, using $s_k$, and for each iteration \cref{safeguard} holds, where $\nu \in (0, 1)$ is a constant.
\end{assumption}

\begin{theorem}[{\cite[Theorem~2.7.]{ByrdKhalfanSchnabel:1996}}] \label{LocalConvergence}
    Consider \cref{TR-SR1Method} satisfying \cref{accuracy1} and \cref{accuracy1} and suppose that \cref{AssumptionsGlobalConvergence} and \cref{AssumptionsLocalConvergence} hold. Then the sequence $\{ x_k \}_k$ generated by \cref{TR-SR1Method} converges $n+l$-step superlinear, i.e. 
    \begin{equation}\label{n+1superlinear}
        \lim_{k \rightarrow \infty} \frac{\lVert x_{k+n+1} - x^* \rVert}{\lVert x_k - x^* \rVert} = 0.
    \end{equation}
\end{theorem}

This result is very interesting  because the concept of trust-region methods can be argued to be appropriate for the Symmetric Rank-One update \cref{directSR1formula} \cite[p.~1025]{ByrdKhalfanSchnabel:1996}.
